<!DOCTYPE html>
<html lang="en">
<head>  <script src="js/analytics.min.js"></script>

<!-- Resource Hints for Performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="dns-prefetch" href="https://fonts.googleapis.com">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap">

  <!-- SEO Meta Tags -->
  <meta name="description" content="Personal website and blog">
  <meta name="author" content="Itzik Ben-Shabat">
  <link rel="canonical" href="https://www.itzikbs.com/blog/posts/2022-02-11-neural-parts-learning-expressive-3d-shape-abstractions-with-invertible-neural-networks.html">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://www.itzikbs.com/blog/posts/2022-02-11-neural-parts-learning-expressive-3d-shape-abstractions-with-invertible-neural-networks.html">
  <meta property="og:title" content="Yizhak Ben-Shabat (Itzik), PhD - Itzik Ben-Shabat">
  <meta property="og:description" content="Personal website and blog">
  <meta property="og:image" content="https://www.itzikbs.com/assets/images/profile/Itzik_Ben_Shabat_portrait.jpg">
  <meta property="og:site_name" content="Itzik Ben-Shabat">
  
  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:url" content="https://www.itzikbs.com/blog/posts/2022-02-11-neural-parts-learning-expressive-3d-shape-abstractions-with-invertible-neural-networks.html">
  <meta name="twitter:title" content="Yizhak Ben-Shabat (Itzik), PhD - Itzik Ben-Shabat">
  <meta name="twitter:description" content="Personal website and blog">
  <meta name="twitter:image" content="https://www.itzikbs.com/assets/images/profile/Itzik_Ben_Shabat_portrait.jpg">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Yizhak Ben-Shabat (Itzik), PhD - Itzik Ben-Shabat</title>
    <link rel="stylesheet" href="../../css/style.min.css?v=5">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        /* Blog post specific styles */
        .blog-post { 
            max-width: 900px; 
            margin: 0 auto; 
            padding: 2rem 1.5rem; 
        }
        
        .post-header { 
            margin-bottom: 3rem; 
            border-bottom: 2px solid var(--border-color); 
            padding-bottom: 1.5rem; 
        }
        
        .post-header h1 { 
            font-size: 2.5rem; 
            margin-bottom: 1rem; 
            color: var(--primary-color); 
            line-height: 1.2;
        }
        
        .post-meta { 
            color: var(--text-light); 
            font-size: 0.95rem; 
        }
        
        .post-meta time { 
            margin-right: 1rem; 
        }
        
        /* Content styling */
        .post-content { 
            line-height: 1.8; 
            font-size: 1.05rem;
        }
        
        .post-content h2,
        .post-content h3.wp-block-heading {
            margin-top: 2.5rem; 
            margin-bottom: 1.25rem; 
            color: var(--primary-color);
            font-weight: 600;
        }
        
        .post-content h2 {
            font-size: 1.75rem;
        }
        
        .post-content h3,
        .post-content h3.wp-block-heading { 
            font-size: 1.4rem;
        }
        
        .post-content p { 
            margin-bottom: 1.25rem; 
        }
        
        .post-content strong {
            color: var(--primary-color);
            font-weight: 600;
        }
        
        /* Images and figures */
        .post-content img { 
            max-width: 100%; 
            height: auto; 
            display: block;
            margin: 2rem auto;
            border-radius: 8px;
            box-shadow: var(--shadow);
        }
        
        .post-content figure {
            margin: 2rem 0;
            text-align: center;
        }
        
        .post-content .wp-block-image,
        .post-content .wp-block-gallery {
            margin: 2rem 0;
        }
        
        .post-content .wp-block-image.aligncenter,
        .post-content figure.aligncenter {
            text-align: center;
        }
        
        .post-content .wp-block-gallery {
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
            justify-content: center;
        }
        
        .post-content .wp-block-gallery figure {
            flex: 1 1 300px;
            max-width: 450px;
            margin: 0;
        }
        
        /* Lists */
        .post-content ul, 
        .post-content ol,
        .post-content .wp-block-list { 
            margin-bottom: 1.5rem; 
            padding-left: 2rem; 
        }
        
        .post-content li { 
            margin-bottom: 0.75rem;
            line-height: 1.7;
        }
        
        .post-content ul {
            list-style-type: disc;
        }
        
        /* Links */
        .post-content a { 
            color: var(--secondary-color); 
            text-decoration: none; 
            border-bottom: 1px solid transparent;
            transition: var(--transition);
        }
        
        .post-content a:hover { 
            border-bottom-color: var(--secondary-color);
        }
        
        /* Code blocks */
        .post-content blockquote { 
            border-left: 4px solid var(--secondary-color); 
            padding-left: 1.5rem; 
            margin: 2rem 0; 
            font-style: italic; 
            color: var(--text-color);
            background-color: var(--bg-light);
            padding: 1rem 1.5rem;
            border-radius: var(--radius);
        }
        
        .post-content code { 
            background-color: var(--bg-light); 
            padding: 0.2rem 0.5rem; 
            border-radius: 4px; 
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        
        .post-content pre { 
            background-color: #1f2937; 
            color: #f9fafb; 
            padding: 1.5rem; 
            border-radius: var(--radius); 
            overflow-x: auto;
            margin: 2rem 0;
        }
        
        .post-content pre code {
            background-color: transparent;
            padding: 0;
        }
        
        /* WordPress specific cleanup */
        .elementor-widget-container {
            width: 100%;
        }
        
        @media (max-width: 768px) {
            .post-header h1 {
                font-size: 2rem;
            }
            
            .blog-post {
                padding: 1rem;
            }
            
            .post-content {
                font-size: 1rem;
            }
        }
    </style>

  <!-- Structured Data (Schema.org) -->
  <script type="application/ld+json">
  {
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Neural Parts: Learning Expressive 3D Shape Abstractions with Invertible Neural Networks",
  "url": "https://www.itzikbs.com/blog/posts/2022-02-11-neural-parts-learning-expressive-3d-shape-abstractions-with-invertible-neural-networks.html",
  "author": {
    "@type": "Person",
    "name": "Itzik Ben-Shabat",
    "url": "https://www.itzikbs.com"
  },
  "publisher": {
    "@type": "Person",
    "name": "Itzik Ben-Shabat"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.itzikbs.com/blog/posts/2022-02-11-neural-parts-learning-expressive-3d-shape-abstractions-with-invertible-neural-networks.html"
  },
  "datePublished": "2022-02-11",
  "dateModified": "2022-02-11",
  "description": "Impressive progress in 3D shape extraction led to representations that can capture object geometries with high fidelity. In parallel, primitive-based methods seek to represent objects as semantical..."
}
  </script>
</head>
<body>
    <nav class="navbar">
        <div class="container">
            <div class="nav-brand">
                <a href="../../index.html">Itzik Ben-Shabat</a>
            </div>
            <button class="nav-toggle" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <ul class="nav-menu">
                <li><a href="../../index.html">About</a></li>
                <li><a href="../../publications.html">Publications</a></li>
                <li><a href="../../blog.html">Blog</a></li>
                <li><a href="../../contact.html">Contact</a></li>
            </ul>
        </div>
    </nav>
    <main>
        <article class="blog-post">
            <header class="post-header">
                <h1>Neural Parts: Learning Expressive 3D Shape Abstractions with Invertible Neural Networks</h1>
                <div class="post-meta">
                    <time datetime="2022-02-11">2022-02-11</time>
                    <span class="author">By Itzik Ben-Shabat</span>
                </div>
            </header>
            <div class="post-content">
                <div class="elementor-element elementor-element-2719b3f elementor-widget elementor-widget-theme-post-content" data-element_type="widget" data-id="2719b3f" data-widget_type="theme-post-content.default">
<div class="elementor-widget-container">
<p>In this episode of the¬†<a href="https://www.itzikbs.com/the-talking-papers-podcast" rel="noreferrer noopener" target="_blank">Talking Papers Podcast</a>, I hosted <a href="https://www.buzzsprout.com/1914034/episodes/10048637">Despoina Paschalidou</a> to chat about her paper ‚ÄúNeural Parts: Learning Expressive 3D Shape Abstractions with Invertible Neural Networks‚Äù, published in CVPR 2021. Neural Parts learns to parse geometrically accurate and semantically consistent part arrangements without any part-level supervision. Despoina is currently a postdoctoral researcher at the <a href="https://geometry.stanford.edu/index.html">Geometric Computation Group</a> at Stanford University. This work was done back when she was still a PhD student at <a href="https://learning-systems.org/">Max Planck ETH Center for Learning Systems</a>. Her unique perspective on interpretable 3D shapes representations makes her stand out in this domain where interpretability is often overlooked. Despoina is the first guest on the podcast that I did not personally know before the interview and she made the experience so pleasant and fun and it was a pleasure recording this episode with her. </p>
<div id="buzzsprout-player-10048637"></div><script charset="utf-8" src="https://www.buzzsprout.com/1914034/10048637-despoina-paschalidou-neural-parts.js?container_id=buzzsprout-player-10048637&amp;player=small" type="text/javascript"></script>
<h2 class="wp-block-heading" id="authors">AUTHORS</h2>
<p id="stephen-gould-richard-hartleydylan-campbell"><a href="https://paschalidoud.github.io/">Despoina Paschalidou¬†</a>, <a href="https://angeloskath.github.io/">Angelos Katharopoulos</a>,¬†<a href="http://cvlibs.net/">Andreas Geiger</a>,¬†<a href="https://www.cs.utoronto.ca/~fidler/">Sanja Fidler</a></p>
<p></p>
<h2 class="wp-block-heading" id="abstract">ABSTRACT</h2>
<p>Impressive progress in 3D shape extraction led to representations that can capture object geometries with high fidelity. In parallel, primitive-based methods seek to represent objects as semantically consistent part arrangements. However, due to the simplicity of existing primitive representations, these methods fail to accurately reconstruct 3D shapes using a small number of primitives/parts. We address the trade-off between reconstruction quality and number of parts with Neural Parts, a novel 3D primitive representation that defines primitives using an Invertible Neural Network (INN) which implements homeomorphic mappings between a sphere and the target object. The INN allows us to compute the inverse mapping of the homomorphism, which in turn, enables the efficient computation of both the implicit surface function of a primitive and its mesh, without any additional post-processing. Our model learns to parse 3D objects into semantically consistent part arrangements without any part-level supervision. Evaluations on ShapeNet, D-FAUST and FreiHAND demonstrate that our primitives can capture complex geometries and thus simultaneously achieve geometrically accurate as well as interpretable reconstructions using an order of magnitude fewer primitives than state-of-the-art shape abstraction methods.</p>
<p></p>
<h2 class="wp-block-heading" id="related-papers">RELATED (WORKS|PAPERS)</h2>
<p>üìö ‚Äú<a href="Unsupervised 3D Keypoint Discovery for Shape Control" rel="noreferrer noopener" target="_blank">KeypointDeformer: Unsupervised 3D Keypoint Discovery for Shape Control</a>‚Äú</p>
<p>üìö ‚Äú<a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Tulsiani_Learning_Shape_Abstractions_CVPR_2017_paper.pdf" rel="noreferrer noopener" target="_blank">Learning Shape Abstractions by Assembling Volumetric Primitives‚Äù: Volumetric primitives</a>‚Äú</p>
<p>üìö ‚Äú<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Paschalidou_Superquadrics_Revisited_Learning_3D_Shape_Parsing_Beyond_Cuboids_CVPR_2019_paper.pdf" rel="noreferrer noopener" target="_blank">Superquadrics Revisited: Learning 3D Shape Parsing beyond Cuboids</a>‚Äú</p>
<p>üìö ‚Äú<a href="Learnable Convex Decomposition" rel="noreferrer noopener" target="_blank">CvxNet: Learnable Convex Decomposition</a>‚Äú<br/><a href="https://proceedings.neurips.cc/paper/2020/hash/59a3adea76fadcb6dd9e54c96fc155d1-Abstract.html" rel="noreferrer noopener" target="_blank">üìö ‚ÄúNeural Star Domain as Primitive Representation</a>‚Äú</p>
<p>üìö ‚Äú<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Genova_Learning_Shape_Templates_With_Structured_Implicit_Functions_ICCV_2019_paper.pdf" rel="noreferrer noopener" target="_blank">Learning Shape Templates with Structured Implicit Functions</a>‚Äú</p>
<h2 class="wp-block-heading" id="links-and-resources">LINKS AND RESOURCES</h2>
<p>üíª Project Page: <a href="https://paschalidoud.github.io/neural_parts" rel="noreferrer noopener" target="_blank">https://paschalidoud.github.io/neural_parts</a></p>
<p>üíª CODE: <a href="https://github.com/paschalidoud/neural_parts" rel="noreferrer noopener" target="_blank">https://github.com/paschalidoud/neural_parts</a></p>
<p>üíª<a href="https://autonomousvision.github.io/neural-parts/" rel="noreferrer noopener" target="_blank">Blog Post</a></p>
<p>üìö <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Paschalidou_Neural_Parts_Learning_Expressive_3D_Shape_Abstractions_With_Invertible_Neural_CVPR_2021_paper.html" rel="noreferrer noopener" target="_blank">Paper Link</a>: ‚ÄúNeural Parts: Learning Expressive 3D Shape Abstractions with Invertible Neural Networks‚Äù</p>
<p><a href="https://www.youtube.com/watch?v=6WK3B0IZJsw&amp;ab_channel=AndreasGeiger" rel="noreferrer noopener" target="_blank">üé•</a> <a href="https://www.youtube.com/watch?v=6WK3B0IZJsw&amp;ab_channel=AndreasGeiger" rel="noreferrer noopener" target="_blank">Paper video</a></p>
<figure class="wp-block-embed is-type-rich is-provider-embed-handler wp-block-embed-embed-handler wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="450" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/XEeGIHaXsik?feature=oembed" title="Talking Papers Podcast with  Despoina Paschalidou - Neural Parts" width="800"></iframe>
</div></figure>
<p></p>
<p>This episode was recorded on April, 25th 2021.</p>
<p></p>
<h2 class="wp-block-heading" id="contact"> CONTACT</h2>
<p>If you would like to be a guest, sponsor or just share your thoughts, feel free to reach out via email: <a class="__cf_email__" data-cfemail="4c382d202725222b623c2d3c293e3f623c23282f2d3f380c2b212d2520622f2321" href="/cdn-cgi/l/email-protection">[email¬†protected]</a></p>
<h2 class="wp-block-heading" id="subscribe-and-follow"><br/>SUBSCRIBE AND FOLLOW</h2>
<p> üéßSubscribe on your favourite podcast app: <a href="https://talking.papers.podcast.itzikbs.com" rel="noreferrer noopener" target="_blank">https://talking.papers.podcast.itzikbs.com</a></p>
<p> üìßSubscribe to our mailing list: <a href="http://eepurl.com/hRznqb" rel="noreferrer noopener" target="_blank">http://eepurl.com/hRznqb</a></p>
<p> üê¶Follow us on Twitter: <a href="https://twitter.com/talking_papers" rel="noreferrer noopener" target="_blank">https://twitter.com/talking_papers</a> </p>
<p>üé•YouTube Channel: </p>
<div class="jp-relatedposts" id="jp-relatedposts">
<h2 class="jp-relatedposts-headline"><em>Related</em></h2>
</div> </div>
</div>
            </div>
        </article>
    </main>
    <script src="../../js/main.min.js".replace(".js", ".min.js")></script>
</body>
</html>
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Yizhak Ben-Shabat (Itzik), PhD - Itzik Ben-Shabat</title>
    <link rel="stylesheet" href="../../css/style.min.css?v=5">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        /* Blog post specific styles */
        .blog-post { 
            max-width: 900px; 
            margin: 0 auto; 
            padding: 2rem 1.5rem; 
        }
        
        .post-header { 
            margin-bottom: 3rem; 
            border-bottom: 2px solid var(--border-color); 
            padding-bottom: 1.5rem; 
        }
        
        .post-header h1 { 
            font-size: 2.5rem; 
            margin-bottom: 1rem; 
            color: var(--primary-color); 
            line-height: 1.2;
        }
        
        .post-meta { 
            color: var(--text-light); 
            font-size: 0.95rem; 
        }
        
        .post-meta time { 
            margin-right: 1rem; 
        }
        
        /* Content styling */
        .post-content { 
            line-height: 1.8; 
            font-size: 1.05rem;
        }
        
        .post-content h2,
        .post-content h3.wp-block-heading {
            margin-top: 2.5rem; 
            margin-bottom: 1.25rem; 
            color: var(--primary-color);
            font-weight: 600;
        }
        
        .post-content h2 {
            font-size: 1.75rem;
        }
        
        .post-content h3,
        .post-content h3.wp-block-heading { 
            font-size: 1.4rem;
        }
        
        .post-content p { 
            margin-bottom: 1.25rem; 
        }
        
        .post-content strong {
            color: var(--primary-color);
            font-weight: 600;
        }
        
        /* Images and figures */
        .post-content img { 
            max-width: 100%; 
            height: auto; 
            display: block;
            margin: 2rem auto;
            border-radius: 8px;
            box-shadow: var(--shadow);
        }
        
        .post-content figure {
            margin: 2rem 0;
            text-align: center;
        }
        
        .post-content .wp-block-image,
        .post-content .wp-block-gallery {
            margin: 2rem 0;
        }
        
        .post-content .wp-block-image.aligncenter,
        .post-content figure.aligncenter {
            text-align: center;
        }
        
        .post-content .wp-block-gallery {
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
            justify-content: center;
        }
        
        .post-content .wp-block-gallery figure {
            flex: 1 1 300px;
            max-width: 450px;
            margin: 0;
        }
        
        /* Lists */
        .post-content ul, 
        .post-content ol,
        .post-content .wp-block-list { 
            margin-bottom: 1.5rem; 
            padding-left: 2rem; 
        }
        
        .post-content li { 
            margin-bottom: 0.75rem;
            line-height: 1.7;
        }
        
        .post-content ul {
            list-style-type: disc;
        }
        
        /* Links */
        .post-content a { 
            color: var(--secondary-color); 
            text-decoration: none; 
            border-bottom: 1px solid transparent;
            transition: var(--transition);
        }
        
        .post-content a:hover { 
            border-bottom-color: var(--secondary-color);
        }
        
        /* Code blocks */
        .post-content blockquote { 
            border-left: 4px solid var(--secondary-color); 
            padding-left: 1.5rem; 
            margin: 2rem 0; 
            font-style: italic; 
            color: var(--text-color);
            background-color: var(--bg-light);
            padding: 1rem 1.5rem;
            border-radius: var(--radius);
        }
        
        .post-content code { 
            background-color: var(--bg-light); 
            padding: 0.2rem 0.5rem; 
            border-radius: 4px; 
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        
        .post-content pre { 
            background-color: #1f2937; 
            color: #f9fafb; 
            padding: 1.5rem; 
            border-radius: var(--radius); 
            overflow-x: auto;
            margin: 2rem 0;
        }
        
        .post-content pre code {
            background-color: transparent;
            padding: 0;
        }
        
        /* WordPress specific cleanup */
        .elementor-widget-container {
            width: 100%;
        }
        
        @media (max-width: 768px) {
            .post-header h1 {
                font-size: 2rem;
            }
            
            .blog-post {
                padding: 1rem;
            }
            
            .post-content {
                font-size: 1rem;
            }
        }
    </style>
</head>
<body>
    <nav class="navbar">
        <div class="container">
            <div class="nav-brand">
                <a href="../../index.html">Itzik Ben-Shabat</a>
            </div>
            <button class="nav-toggle" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <ul class="nav-menu">
                <li><a href="../../index.html">About</a></li>
                <li><a href="../../publications.html">Publications</a></li>
                <li><a href="../../blog.html">Blog</a></li>
                <li><a href="../../contact.html">Contact</a></li>
            </ul>
        </div>
    </nav>
    <main>
        <article class="blog-post">
            <header class="post-header">
                <h1>NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection</h1>
                <div class="post-meta">
                    <time datetime="2023-09-07">2023-09-07</time>
                    <span class="author">By Itzik Ben-Shabat</span>
                </div>
            </header>
            <div class="post-content">
                <div class="elementor-element elementor-element-2719b3f elementor-widget elementor-widget-theme-post-content" data-element_type="widget" data-id="2719b3f" data-widget_type="theme-post-content.default">
<div class="elementor-widget-container">
<p>In this episode of the¬†<a href="https://www.itzikbs.com/the-talking-papers-podcast" rel="noreferrer noopener" target="_blank">Talking Papers Podcast</a>, I hosted Chenfeng Xu. We had a great chat about his paper ‚ÄúNeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection‚Äù, published in ICCV 2023. </p>
<p>In recent times, NeRF has gained widespread prominence, and the field of 3D detection has encountered well-recognized challenges. The principal contribution of this study lies in its ability to address the detection task while simultaneously training a NeRF model and enabling it to generalize to previously unobserved scenes. Although the computer vision community has been actively addressing various tasks related to images and point clouds for an extended period, it is particularly invigorating to witness the application of NeRF representation in tackling this specific challenge.</p>
<p></p>
<p>Chenfeng is currently a Ph.D. candidate at UC Berkeley, collaborating with Prof. Masayoshi Tomizuka and Prof. Kurt Keutzer. His affiliations include Berkeley DeepDrive (BDD) and Berkeley AI Research (BAIR), along with the MSC lab and PALLAS. His research endeavors revolve around enhancing computational and data efficiency in machine perception, with a primary focus on temporal-3D scenes and their downstream applications. He brings together traditionally separate approaches from geometric computing and deep learning to establish both theoretical frameworks and practical algorithms for temporal-3D representations. His work spans a wide range of applications, including autonomous driving, robotics, AR/VR, and consistently demonstrates remarkable efficiency through extensive experimentation. I am eagerly looking forward to see his upcoming research papers. </p>
<p><br/></p>
<div id="buzzsprout-player-13543293"></div><script charset="utf-8" src="https://www.buzzsprout.com/1914034/13543293-nerf-det-chenfeng-xu.js?container_id=buzzsprout-player-13543293&amp;player=small" type="text/javascript"></script>
<h3 class="wp-block-heading" id="authors">AUTHORS</h3>
<p>Chenfeng Xu, Bichen Wu, Ji Hou, Sam Tsai, Ruilong Li, Jialiang Wang, Wei Zhan, Zijian He, Peter Vajda, Kurt Keutzer, Masayoshi Tomizuka<br/></p>
<h3 class="wp-block-heading" id="abstract">ABSTRACT</h3>
<p>¬†We consider the problem of learning a function that can estimate the 3D shape, articulation, viewpoint, texture, and lighting of an articulated animal like a horse, given a single test image. We present a new method, dubbed MagicPony, that learns this function purely from in-the-wild single-view images of the object category, with minimal assumptions about the topology of deformation. At its core is an implicit-explicit representation of articulated shape and appearance, combining the strengths of neural fields and meshes. In order to help the model understand an object‚Äôs shape and pose, we distil the knowledge captured by an off-the-shelf self-supervised vision transformer and fuse it into the 3D model. To NeRF-Det is a novel method for 3D detection with posed RGB images as input. Our method makes novel use of NeRF in an end-to-end manner to explicitly estimate 3D geometry, thereby improving 3D detection performance. Specifically, to avoid the significant extra latency associated with per-scene optimization of NeRF, we introduce sufficient geometry priors to enhance the generalizability of NeRF-MLP. We subtly connect the detection and NeRF branches through a shared MLP, enabling an efficient adaptation of NeRF to detection and yielding geometry-aware volumetric representations for 3D detection. As a result of our joint-training design, NeRF-Det is able to generalize well to unseen scenes for object detection, view synthesis, and depth estimation tasks without per-scene optimization.</p>
<p>¬†</p>
<p></p>
<h3 class="wp-block-heading" id="related-papers">RELATED PAPERS</h3>
<p>üìö<a href="https://www.matthewtancik.com/nerf" rel="noreferrer noopener" target="_blank">NeRF</a></p>
<p>üìö<a href="https://openaccess.thecvf.com/content/WACV2022/papers/Rukhovich_ImVoxelNet_Image_to_Voxels_Projection_for_Monocular_and_Multi-View_General-Purpose_WACV_2022_paper.pdf" rel="noreferrer noopener" target="_blank">ImageVoxelNet</a></p>
<p></p>
<p></p>
<h3 class="wp-block-heading">LINKS AND RESOURCES</h3>
<p>üìö <a href="https://arxiv.org/abs/2307.14620">Paper</a></p>
<p>üíª<a href="https://chenfengxu714.github.io/nerfdet/">Project page</a></p>
<p>üíª<a href="https://github.com/facebookresearch/NeRF-Det">Code</a></p>
<p></p>
<p>To stay up to date with their latest research, follow on:</p>
<p>üë®üèª‚Äçüéì<a href="https://www.chenfengx.com">Personal page</a></p>
<p>üê¶<a href="https://twitter.com/Chenfeng_X">Twitter</a></p>
<p>üë®üèª‚Äçüéì<a href="https://scholar.google.com/citations?hl=en&amp;user=RpqvaTUAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Google Scholar</a></p>
<p></p>
<p></p>
<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="450" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/YNTYQ3vYJYE?feature=oembed" title="NeRF-Det (ICCV 2023) with Chenfeng Xu on Talking papers" width="800"></iframe>
</div></figure>
<p>Recorded on August 8th 2023.</p>
<p><br/><br/>CONTACT</p>
<p>If you would like to be a guest, sponsor or share your thoughts, feel free to reach out via email: <a class="__cf_email__" data-cfemail="4c382d202725222b623c2d3c293e3f623c23282f2d3f380c2b212d2520622f2321" href="/cdn-cgi/l/email-protection">[email¬†protected]</a></p>
<p></p>
<h3 class="wp-block-heading">SUBSCRIBE AND FOLLOW</h3>
<p>üéßSubscribe on your favourite podcast app: <a href="https://talking.papers.podcast.itzikbs.com" rel="noreferrer noopener" target="_blank">https://talking.papers.podcast.itzikbs.com</a></p>
<p>üìßSubscribe to our mailing list: <a href="http://eepurl.com/hRznqb" rel="noreferrer noopener" target="_blank">http://eepurl.com/hRznqb</a></p>
<p>üê¶Follow us on Twitter: <a href="https://twitter.com/talking_papers" rel="noreferrer noopener" target="_blank">https://twitter.com/talking_papers</a></p>
<p>üé•YouTube Channel: </p>
<p></p>
<p></p>
<p></p>
<div class="jp-relatedposts" id="jp-relatedposts">
<h3 class="jp-relatedposts-headline"><em>Related</em></h3>
</div> </div>
</div>
            </div>
        </article>
    </main>
    <script src="../../js/main.min.js".replace(".js", ".min.js")></script>
</body>
</html>
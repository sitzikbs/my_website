<!DOCTYPE html>
<html lang="en">
<head>  <script src="js/analytics.min.js"></script>

<!-- Resource Hints for Performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="dns-prefetch" href="https://fonts.googleapis.com">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap">

  <!-- SEO Meta Tags -->
  <meta name="description" content="Personal website and blog">
  <meta name="author" content="Itzik Ben-Shabat">
  <link rel="canonical" href="https://www.itzikbs.com/blog/posts/2022-07-18-icon-implicit-clothed-humans-obtained-from-normals.html">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://www.itzikbs.com/blog/posts/2022-07-18-icon-implicit-clothed-humans-obtained-from-normals.html">
  <meta property="og:title" content="Yizhak Ben-Shabat (Itzik), PhD - Itzik Ben-Shabat">
  <meta property="og:description" content="Personal website and blog">
  <meta property="og:image" content="https://www.itzikbs.com/assets/images/profile/Itzik_Ben_Shabat_portrait.jpg">
  <meta property="og:site_name" content="Itzik Ben-Shabat">
  
  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:url" content="https://www.itzikbs.com/blog/posts/2022-07-18-icon-implicit-clothed-humans-obtained-from-normals.html">
  <meta name="twitter:title" content="Yizhak Ben-Shabat (Itzik), PhD - Itzik Ben-Shabat">
  <meta name="twitter:description" content="Personal website and blog">
  <meta name="twitter:image" content="https://www.itzikbs.com/assets/images/profile/Itzik_Ben_Shabat_portrait.jpg">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Yizhak Ben-Shabat (Itzik), PhD - Itzik Ben-Shabat</title>
    <link rel="stylesheet" href="../../css/style.min.css?v=5">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        /* Blog post specific styles */
        .blog-post { 
            max-width: 900px; 
            margin: 0 auto; 
            padding: 2rem 1.5rem; 
        }
        
        .post-header { 
            margin-bottom: 3rem; 
            border-bottom: 2px solid var(--border-color); 
            padding-bottom: 1.5rem; 
        }
        
        .post-header h1 { 
            font-size: 2.5rem; 
            margin-bottom: 1rem; 
            color: var(--primary-color); 
            line-height: 1.2;
        }
        
        .post-meta { 
            color: var(--text-light); 
            font-size: 0.95rem; 
        }
        
        .post-meta time { 
            margin-right: 1rem; 
        }
        
        /* Content styling */
        .post-content { 
            line-height: 1.8; 
            font-size: 1.05rem;
        }
        
        .post-content h2,
        .post-content h3.wp-block-heading {
            margin-top: 2.5rem; 
            margin-bottom: 1.25rem; 
            color: var(--primary-color);
            font-weight: 600;
        }
        
        .post-content h2 {
            font-size: 1.75rem;
        }
        
        .post-content h3,
        .post-content h3.wp-block-heading { 
            font-size: 1.4rem;
        }
        
        .post-content p { 
            margin-bottom: 1.25rem; 
        }
        
        .post-content strong {
            color: var(--primary-color);
            font-weight: 600;
        }
        
        /* Images and figures */
        .post-content img { 
            max-width: 100%; 
            height: auto; 
            display: block;
            margin: 2rem auto;
            border-radius: 8px;
            box-shadow: var(--shadow);
        }
        
        .post-content figure {
            margin: 2rem 0;
            text-align: center;
        }
        
        .post-content .wp-block-image,
        .post-content .wp-block-gallery {
            margin: 2rem 0;
        }
        
        .post-content .wp-block-image.aligncenter,
        .post-content figure.aligncenter {
            text-align: center;
        }
        
        .post-content .wp-block-gallery {
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
            justify-content: center;
        }
        
        .post-content .wp-block-gallery figure {
            flex: 1 1 300px;
            max-width: 450px;
            margin: 0;
        }
        
        /* Lists */
        .post-content ul, 
        .post-content ol,
        .post-content .wp-block-list { 
            margin-bottom: 1.5rem; 
            padding-left: 2rem; 
        }
        
        .post-content li { 
            margin-bottom: 0.75rem;
            line-height: 1.7;
        }
        
        .post-content ul {
            list-style-type: disc;
        }
        
        /* Links */
        .post-content a { 
            color: var(--secondary-color); 
            text-decoration: none; 
            border-bottom: 1px solid transparent;
            transition: var(--transition);
        }
        
        .post-content a:hover { 
            border-bottom-color: var(--secondary-color);
        }
        
        /* Code blocks */
        .post-content blockquote { 
            border-left: 4px solid var(--secondary-color); 
            padding-left: 1.5rem; 
            margin: 2rem 0; 
            font-style: italic; 
            color: var(--text-color);
            background-color: var(--bg-light);
            padding: 1rem 1.5rem;
            border-radius: var(--radius);
        }
        
        .post-content code { 
            background-color: var(--bg-light); 
            padding: 0.2rem 0.5rem; 
            border-radius: 4px; 
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        
        .post-content pre { 
            background-color: #1f2937; 
            color: #f9fafb; 
            padding: 1.5rem; 
            border-radius: var(--radius); 
            overflow-x: auto;
            margin: 2rem 0;
        }
        
        .post-content pre code {
            background-color: transparent;
            padding: 0;
        }
        
        /* WordPress specific cleanup */
        .elementor-widget-container {
            width: 100%;
        }
        
        @media (max-width: 768px) {
            .post-header h1 {
                font-size: 2rem;
            }
            
            .blog-post {
                padding: 1rem;
            }
            
            .post-content {
                font-size: 1rem;
            }
        }
    </style>

  <!-- Structured Data (Schema.org) -->
  <script type="application/ld+json">
  {
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "ICON: Implicit Clothed humans Obtained from Normals",
  "url": "https://www.itzikbs.com/blog/posts/2022-07-18-icon-implicit-clothed-humans-obtained-from-normals.html",
  "author": {
    "@type": "Person",
    "name": "Itzik Ben-Shabat",
    "url": "https://www.itzikbs.com"
  },
  "publisher": {
    "@type": "Person",
    "name": "Itzik Ben-Shabat"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.itzikbs.com/blog/posts/2022-07-18-icon-implicit-clothed-humans-obtained-from-normals.html"
  },
  "datePublished": "2022-07-18",
  "dateModified": "2022-07-18",
  "description": "In this paper, they take on the task of reconstructing an animatable\u00a0human avatar from multiple images. Their key ideas are to use local features which are more robust to pose estimation error and ..."
}
  </script>
</head>
<body>
  <a href="#main-content" class="skip-link">Skip to main content</a>
    <nav class="navbar">
        <div class="container">
            <div class="nav-brand">
                <a href="../../index.html">Itzik Ben-Shabat</a>
            </div>
            <button class="nav-toggle" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <ul class="nav-menu">
                <li><a href="../../index.html">About</a></li>
                <li><a href="../../publications.html">Publications</a></li>
                <li><a href="../../blog.html">Blog</a></li>
                <li><a href="../../contact.html">Contact</a></li>
            </ul>
        </div>
    </nav>
    <main>
        <article class="blog-post">
            <header class="post-header">
                <h1>ICON: Implicit Clothed humans Obtained from Normals</h1>
                <div class="post-meta">
                    <time datetime="2022-07-18">2022-07-18</time>
                    <span class="author">By Itzik Ben-Shabat</span>
                </div>
            </header>
            <div class="post-content">
                <div class="elementor-element elementor-element-2719b3f elementor-widget elementor-widget-theme-post-content" data-element_type="widget" data-id="2719b3f" data-widget_type="theme-post-content.default">
<div class="elementor-widget-container">
<p>In this episode of the¬†<a href="https://www.itzikbs.com/the-talking-papers-podcast" rel="noreferrer noopener" target="_blank">Talking Papers Podcast</a>, I hosted <a href="https://xiuyuliang.cn/" rel="noreferrer noopener" target="_blank">Yuliang Xiu</a> to chat about his paper ‚Äú<a href="Implicit Clothed humans Obtained from Normals" rel="noreferrer noopener" target="_blank">ICON: Implicit Clothed humans Obtained from Normals</a>‚Äù, published in CVPR 2022. </p>
<p>In this paper, they take on the task of reconstructing an animatable¬†human avatar from multiple images. Their key ideas are to use local features which are more robust to pose estimation error and exploit the SMPL(-X) body model to infer clothed humans (conditioned on the normals).  Additionally, they propose an inference-time feedback loop that alternates between refining the body‚Äôs normals and the shape. </p>
<p>I am looking forward to meeting Yuliang in person at CVPR 2022. It was a pleasure hosting him on the podcast. </p>
<div id="buzzsprout-player-10466744"></div><script charset="utf-8" src="https://www.buzzsprout.com/1914034/10466744-yuliang-xiu-icon.js?container_id=buzzsprout-player-10466744&amp;player=small" type="text/javascript"></script>
<h2 class="wp-block-heading" id="authors">AUTHORS</h2>
<p id="stephen-gould-richard-hartleydylan-campbell"><em>Yuliang Xiu, Jinlong Yang, Dimitrios Tzionas, Michael J. Black</em></p>
<p>¬†</p>
<h2 class="wp-block-heading" id="abstract">ABSTRACT</h2>
<p>Current methods for learning realistic and animatable 3D clothed avatars need either posed 3D scans or 2D images with carefully controlled user poses. In contrast, our goal is to learn an avatar from only 2D images of people in unconstrained poses. Given a set of images, our method estimates a detailed 3D surface from each image and then combines these into an animatable avatar. Implicit functions are well suited to the first task, as they can capture details like hair and clothes. Current methods, however, are not robust to varied human poses and often produce 3D surfaces with broken or disembodied limbs, missing details, or non-human shapes. The problem is that these methods use global feature encoders that are sensitive to global pose. To address this, we propose ICON (‚ÄúImplicit Clothed humans Obtained from Normals‚Äù), which, instead, uses local features. ICON has two main modules, both of which exploit the SMPL(-X) body model. First, ICON infers detailed clothed-human normals (front/back) conditioned on the SMPL(-X) normals. Second, a visibility-aware implicit surface regressor produces an iso-surface of a human occupancy field. Importantly, at inference time, a feedback loop alternates between refining the SMPL(-X) mesh using the inferred clothed normals and then refining the normals. Given multiple reconstructed frames of a subject in varied poses, we use SCANimate to produce an animatable avatar from them. Evaluation on the AGORA and CAPE datasets shows that ICON outperforms the state of the art in reconstruction, even with heavily limited training data. Additionally, it is much more robust to out-of-distribution samples, e.g., in-the-wild poses/images and out-of-frame cropping. ICON takes a step towards robust 3D clothed human reconstruction from in-the-wild images. This enables creating avatars directly from video with personalized and natural pose-dependent cloth deformation.</p>
<p>¬†</p>
<h2 class="wp-block-heading" id="related-papers">RELATED (WORKS|PAPERS)</h2>
<p>üìö<a href="https://xiuyuliang.cn/monoport/" rel="noreferrer noopener" target="_blank">Monocular Real-Time Volumetric Performance Capture</a></p>
<p>üìö<a href="https://shunsukesaito.github.io/PIFu/" rel="noreferrer noopener" target="_blank">PIFu</a></p>
<p>üìö<a href="https://shunsukesaito.github.io/PIFuHD/" rel="noreferrer noopener" target="_blank">PIFuHD</a></p>
<h2 class="wp-block-heading">LINKS AND RESOURCES</h2>
<p>üíª<a href="https://icon.is.tue.mpg.de/" rel="noreferrer noopener" target="_blank">Project website</a></p>
<p>üíª<a href="https://github.com/yuliangxiu/ICON" rel="noreferrer noopener" target="_blank">Code</a></p>
<p>üìö <a href="https://arxiv.org/abs/2112.09127" rel="noreferrer noopener" target="_blank">Paper</a></p>
<p></p>
<p></p>
<p>To stay up to date with Yulian‚Äôs latest research, follow him on:</p>
<p>üë®üèª‚Äçüéì <a href="https://xiuyuliang.cn/" rel="noreferrer noopener" target="_blank">Yulian‚Äôgs homepage</a></p>
<p>üéì</p>
<p>üê¶<a href="https://twitter.com/yuliangxiu" rel="noreferrer noopener" target="_blank">Twitter</a></p>
<p>üë®üèª‚Äçüéì<a href="https://www.linkedin.com/in/yuliangxiu" rel="noreferrer noopener" target="_blank">LinkedIn</a></p>
<p></p>
<p></p>
<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="450" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/JPk9gu_dQD0?feature=oembed" title="ICON: Implicit Clothed humans Obtained from Normals (CVPR2022) - Yuliang Xiu on Talking Papers" width="800"></iframe>
</div></figure>
<p>Recorded on March 11th 2022.</p>
<h2 class="wp-block-heading"><br/>CONTACT</h2>
<p>If you would like to be a guest, sponsor or just share your thoughts, feel free to reach out via email: <a class="__cf_email__" data-cfemail="a8dcc9c4c3c1c6cf86d8c9d8cddadb86d8c7cccbc9dbdce8cfc5c9c1c486cbc7c5" href="/cdn-cgi/l/email-protection">[email¬†protected]</a></p>
<p></p>
<h2 class="wp-block-heading">SUBSCRIBE AND FOLLOW</h2>
<p>üéßSubscribe on your favourite podcast app: <a href="https://talking.papers.podcast.itzikbs.com" rel="noreferrer noopener" target="_blank">https://talking.papers.podcast.itzikbs.com</a></p>
<p>üìßSubscribe to our mailing list: <a href="http://eepurl.com/hRznqb" rel="noreferrer noopener" target="_blank">http://eepurl.com/hRznqb</a></p>
<p>üê¶Follow us on Twitter: <a href="https://twitter.com/talking_papers" rel="noreferrer noopener" target="_blank">https://twitter.com/talking_papers</a></p>
<p>üé•YouTube Channel: </p>
<p></p>
<p></p>
<p></p>
<div class="jp-relatedposts" id="jp-relatedposts">
<h2 class="jp-relatedposts-headline"><em>Related</em></h2>
</div> </div>
</div>
            </div>
        </article>
    </main>
    <script src="../../js/main.min.js".replace(".js", ".min.js")></script>
</body>
</html>
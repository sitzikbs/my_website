---
layout: layouts/blog-post.njk
title: "MobileBrick: Building LEGO for 3D Reconstruction on Mobile Devices"
date: 2023-06-14
author: Itzik Ben-Shabat
permalink: "/blog/posts/2023-06-14-mobilebrick.html"
---

<div class="post-content">
{% raw %}




<p>In this episode of the <a href="https://www.itzikbs.com/the-talking-papers-podcast" rel="noreferrer noopener" target="_blank">Talking Papers Podcast</a>, I hosted Kejie Li to chat about his CVPR 2023 paper â€œMobileBrick: Building LEGO for 3D Reconstruction on Mobile Devicesâ€.</p>
<p>In this paper, they proposed a new dataset and paradigm for evaluating 3D object reconstruction. It is very difficult to create a digital twin of 3D objects, even with expensive sensors. They introduce a new RGBD dataset, captured from a mobile device. The nice trick to obtaining the ground truth is that they used LEGO bricks that have an exact CAD model. There are two very interesting finds here. First, NeRF and NeuS work great and second, you shouldnâ€™t use low-quality depth if you have high-resolution RGB. </p>
<p></p>
<p>Kejie is currently a research scientist at ByteDance/ TikTok. When writing this paper he was a postdoc at Kejie is currently a research scientist at ByteDance/ TikTok. When writing this paper he was a postdoc at Oxford, working with Professor Philip Torr and Professor Victor Prisacariu. Prior to this, he successfully obtained his PhD from the University of Adelaide, under the guidance of Professor Ian Reid. Although we hadnâ€™t crossed paths until this episode, we both have some common ground in our CVs, having been affiliated with different nodes of the ACRV (Adelaide for him and ANU for me). Iâ€™m excited to see what he comes up with next, and eagerly await his future endeavours.</p>
<p></p>
<p></p>
<div id="buzzsprout-player-13033756">{% endraw %}
</div><script charset="utf-8" src="https://www.buzzsprout.com/1914034/13033756-mobilebrick-kejie-li.js?container_id=buzzsprout-player-13033756&amp;player=small" type="text/javascript"></script>
<h2 class="wp-block-heading" id="authors">AUTHORS</h2>
<p id="stephen-gould-richard-hartleydylan-campbell"><em>Kejie Li,Â Jia-Wang Bian,Â Robert Castle,Â Philip H.S. Torr,Â Victor Adrian Prisacariu</em></p>
<p></p>
<h2 class="wp-block-heading" id="abstract">ABSTRACT</h2>
<p>Â </p>
<p>High-quality 3D ground-truth shapes are critical for 3D object reconstruction evaluation. However, it is difficult to create a replica of an object in reality, and even 3D reconstructions generated by 3D scanners have artefacts that cause biases in evaluation. To address this issue, we introduce a novel multi-view RGBD dataset captured using a mobile device, which includes highly precise 3D ground-truth annotations for 153 object models featuring a diverse set of 3D structures. We obtain precise 3D ground-truth shape without relying on high-end 3D scanners by utilising LEGO models with known geometry as the 3D structures for image capture. The distinct data modality offered by high-resolution RGB images and low-resolution depth maps captured on a mobile device, when combined with precise 3D geometry annotations, presents a unique opportunity for future research on high-fidelity 3D reconstruction. Furthermore, we evaluate a range of 3D reconstruction algorithms on the proposed dataset.</p>
<p>Â </p>
<p></p>
<h2 class="wp-block-heading" id="related-papers">RELATED (WORKS|PAPERS)</h2>
<p>ğŸ“š<a href="https://colmap.github.io/" rel="noreferrer noopener" target="_blank">COLMAP</a></p>
<p>ğŸ“š<a href="https://www.matthewtancik.com/nerf" rel="noreferrer noopener" target="_blank">NeRF</a></p>
<p>ğŸ“š<a href="https://lingjie0206.github.io/papers/NeuS/" rel="noreferrer noopener" target="_blank">NeuS</a></p>
<p>ğŸ“š<a href="https://ai.facebook.com/datasets/CO3D-dataset/" rel="noreferrer noopener" target="_blank">CO3D</a></p>
<h2 class="wp-block-heading">LINKS AND RESOURCES</h2>
<p>ğŸ“š <a href="https://arxiv.org/abs/2303.01932">Paper</a></p>
<p>ğŸ’»<a href="https://code.active.vision/MobileBrick/" rel="noreferrer noopener" target="_blank">Project page</a></p>
<p>ğŸ’»<a href="https://github.com/ActiveVisionLab/MobileBrick" rel="noreferrer noopener" target="_blank">Code</a></p>
<p>To stay up to date with Jiahaoâ€™s latest research, follow him on:</p>
<p>ğŸ‘¨ğŸ»â€ğŸ“<a href="https://likojack.github.io/kejieli/#/home" rel="noreferrer noopener" target="_blank">Personal page</a></p>
<p>ğŸ‘¨ğŸ»â€ğŸ“<a href="https://scholar.google.com.au/citations?user=JBwsoCUAAAAJ&amp;hl=en" rel="noreferrer noopener" target="_blank">Google Scholar</a></p>
<p>ğŸ¦<a href="https://twitter.com/kejie_li" rel="noreferrer noopener" target="_blank">Twitter</a></p>
<p></p>
<p></p>
<figure class="wp-block-embed is-type-rich is-provider-embed-handler wp-block-embed-embed-handler wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="450" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/mpQiLEm955s?feature=oembed" title="MobileBrick  (CVPR 2023) with Kejie Li on Talking papers" width="800"></iframe>
</div></figure>
<p>Recorded on May 8th 2023.</p>
<h3 class="wp-block-heading">SPONSOR</h3>
<p>This episode was sponsored by YOOM. YOOM is an Israeli startup dedicated to volumetric video creation. They were voted as the 2022 best start-up to work for by Dunâ€™s 100.<br/><a href="https://www.yoom.com/careers" rel="noreferrer noopener" target="_blank">Join their team</a> that works on geometric deep learning research, implicit representations of 3D humans, NeRFs, and 3D/4D generative models.</p>
<p><br/>Visit <a href="https://www.yoom.com/" rel="noreferrer noopener" target="_blank">YOOM.com</a>.</p>
<h2 class="wp-block-heading"><br/>CONTACT</h2>
<p>If you would like to be a guest, sponsor or share your thoughts, feel free to reach out via email: talking (dor) papers (dot) podcast(at) gmail (dot) com</p>
<p></p>
<h2 class="wp-block-heading">SUBSCRIBE AND FOLLOW</h2>
<p>ğŸ§Subscribe on your favourite podcast app: <a href="https://talking.papers.podcast.itzikbs.com" rel="noreferrer noopener" target="_blank">https://talking.papers.podcast.itzikbs.com</a></p>
<p>ğŸ“§Subscribe to our mailing list: <a href="http://eepurl.com/hRznqb" rel="noreferrer noopener" target="_blank">http://eepurl.com/hRznqb</a></p>
<p>ğŸ¦Follow us on Twitter: <a href="https://twitter.com/talking_papers" rel="noreferrer noopener" target="_blank">https://twitter.com/talking_papers</a></p>
<p>ğŸ¥YouTube Channel: </p>
<p></p>
<p></p>
<p></p>
 

</div>
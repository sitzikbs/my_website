---
layout: layouts/blog-post.njk
title: "CLIPasso: Semantically-Aware Object Sketching"
date: 2023-03-29
author: Itzik Ben-Shabat
permalink: "/blog/posts/2023-03-29-clipasso.html"
---

<div class="post-content">
{% raw %}




<p>In this episode of theÂ <a href="https://www.itzikbs.com/the-talking-papers-podcast" rel="noreferrer noopener" target="_blank">Talking Papers Podcast</a>, I hosted <a href="https://yael-vinker.github.io/website/index.html">Yael Vinker</a>. We had a great chat about her paper â€œ<a href="https://clipasso.github.io/clipasso/" rel="noreferrer noopener" target="_blank">CLIPasso: Semantically-Aware Object Sketching</a>â€, SIGGRAPH 2022 best paper award winner. </p>
<p>In this paper, they convert images into sketches with different levels of abstraction.  They avoid the need for sketch datasets by using the well-known CLIP model to distil the semantic concepts from sketches and images. There is no network training here, just optimizing the control points of Bezier curves to model the sketch strokes (initialized by a saliency map). How is this differentiable? They use a differentiable rasterizer. The degree of abstraction is controlled by the number of strokes. Donâ€™t miss the amazing <a href="https://replicate.com/yael-vinker/clipasso" rel="noreferrer noopener" target="_blank">demo </a>they created.</p>
<p></p>
<p>Yael is currently a PhD student at Tel Aviv University. Her research focus is on computer vision, machine learning, and computer graphics with a unique twist of combining art and technology. This work was done as part of her internship at EPFL. I met Yael at <a href="https://www.youtube.com/watch?v=f1MMYJ38GZ0&amp;list=PLNiWLB_wsOg6EI9H_iuGAyIzWTEE9gFgI&amp;index=12&amp;ab_channel=TAUVOD" rel="noreferrer noopener" target="_blank">Israelâ€™s Vision Day 2022</a>. After she gave an amazing talk on this paper, I knew I wanted to host her on the podcast, and here we are today. In our conversation, I particularly liked her approach towards research and her aspiration to start a new field. I feel this should be the goal of any PhD student. Her artistic background, combined with computer science gives her a very special skillset in the communities landscape. </p>
<p>I am really looking forward to seeing what papers she will draw up next (pun intended). </p>
<p><br/></p>
<p></p>
<div id="buzzsprout-player-12427776">{% endraw %}
</div><script charset="utf-8" src="https://www.buzzsprout.com/1914034/12427776-clipasso-yael-vinker.js?container_id=buzzsprout-player-12427776&amp;player=small" type="text/javascript"></script>
<h2 class="wp-block-heading" id="authors">AUTHORS</h2>
<p id="stephen-gould-richard-hartleydylan-campbell"><em><a href="https://yaelvi116.wixsite.com/mysite" rel="noreferrer noopener" target="_blank">Yael Vinker</a>,Â <a href="https://pajouheshgar.github.io/" rel="noreferrer noopener" target="_blank">Ehsan Pajouheshgar</a>,Â <a href="https://jessica-bo.github.io/" rel="noreferrer noopener" target="_blank">Jessica Y. Bo</a>,Â <a href="https://roman-bachmann.github.io/" rel="noreferrer noopener" target="_blank">Roman Bachmann</a>, <a href="https://www.cs.tau.ac.il/~amberman/" rel="noreferrer noopener" target="_blank">Amit Haim Bermano</a>,Â <a href="https://danielcohenor.com/" rel="noreferrer noopener" target="_blank">Daniel Cohen-Or</a>,Â <a href="https://vilab.epfl.ch/zamir/" rel="noreferrer noopener" target="_blank">Amir Zamir</a>,Â <a href="https://faculty.idc.ac.il/arik/site/index.asp" rel="noreferrer noopener" target="_blank">Ariel Shamir</a></em></p>
<p><br/></p>
<h2 class="wp-block-heading" id="abstract">ABSTRACT</h2>
<p>Â </p>
<p>Abstraction is at the heart of sketching due to the simple and minimal nature of line drawings. Abstraction entails identifying the essential visual properties of an object or scene, which requires semantic understanding and prior knowledge of high-level concepts. Abstract depictions are therefore challenging for artists, and even more so for machines. We present an object sketching method that can achieve different levels of abstraction, guided by geometric and semantic simplifications. While sketch generation methods often rely on explicit sketch datasets for training, we utilize the remarkable ability of CLIP (Contrastive-Language-Image-Pretraining) to distil semantic concepts from sketches and images alike. We define a sketch as a set of BÃ©zier curves and use a differentiable rasterizer to optimize the parameters of the curves directly with respect to a CLIP-based perceptual loss. The abstraction degree is controlled by varying the number of strokes. The generated sketches demonstrate multiple levels of abstraction while maintaining recognizability, underlying structure, and essential visual components of the subject drawn.</p>
<p>Â </p>
<p></p>
<h2 class="wp-block-heading" id="related-papers">RELATED (WORKS|PAPERS)</h2>
<p>ğŸ“š<a href="https://openai.com/research/clip">CLIP: Connecting Text and Images</a></p>
<p>ğŸ“š<a href="https://people.csail.mit.edu/tzumao/diffvg/" rel="noreferrer noopener" target="_blank">Differentiable Vector Graphics Rasterization for Editing and Learning</a></p>
<p></p>
<p></p>
<h2 class="wp-block-heading">LINKS AND RESOURCES</h2>
<p>ğŸ“š <a href="https://arxiv.org/pdf/2202.05822.pdf" rel="noreferrer noopener" target="_blank">Paper</a></p>
<p>ğŸ’»<a href="https://clipasso.github.io/clipasso/" rel="noreferrer noopener" target="_blank">Project page</a></p>
<p></p>
<p></p>
<p>To stay up to date with Yaelâ€™s latest research, follow her on:</p>
<p>ğŸ‘¨ğŸ»â€ğŸ“<a href="https://yaelvi116.wixsite.com/mysite">Personal page</a></p>
<p>ğŸ¦<a href="https://twitter.com/YVinker" rel="noreferrer noopener" target="_blank">Twitter</a></p>
<p>ğŸ‘¨ğŸ»â€ğŸ“<a href="https://scholar.google.com/citations?user=KhqjcM8AAAAJ&amp;hl=en&amp;oi=ao" rel="noreferrer noopener" target="_blank">Google Scholar</a></p>
<p>ğŸ‘¨ğŸ»â€ğŸ“<a href="https://www.linkedin.com/in/yael-vinker-a91a00157/" rel="noreferrer noopener" target="_blank">LinkedIn</a></p>
<p></p>
<p></p>
<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="450" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/HJMXykMEKTQ?feature=oembed" title="CLIPasso (SIGGRAPH 2022 best paper) with Yael Vinker on Talking papers" width="800"></iframe>
</div></figure>
<p>Recorded on February 1st 2023.</p>
<h2 class="wp-block-heading"><br/>CONTACT</h2>
<p>If you would like to be a guest, sponsor or share your thoughts, feel free to reach out via email: <a class="__cf_email__" data-cfemail="97e3f6fbfcfef9f0b9e7f6e7f2e5e4b9e7f8f3f4f6e4e3d7f0faf6fefbb9f4f8fa" href="/cdn-cgi/l/email-protection">[emailÂ protected]</a></p>
<p></p>
<h2 class="wp-block-heading">SUBSCRIBE AND FOLLOW</h2>
<p>ğŸ§Subscribe on your favourite podcast app: <a href="https://talking.papers.podcast.itzikbs.com" rel="noreferrer noopener" target="_blank">https://talking.papers.podcast.itzikbs.com</a></p>
<p>ğŸ“§Subscribe to our mailing list: <a href="http://eepurl.com/hRznqb" rel="noreferrer noopener" target="_blank">http://eepurl.com/hRznqb</a></p>
<p>ğŸ¦Follow us on Twitter: <a href="https://twitter.com/talking_papers" rel="noreferrer noopener" target="_blank">https://twitter.com/talking_papers</a></p>
<p>ğŸ¥YouTube Channel: </p>
<p></p>
<p></p>
<p></p>
 

</div>